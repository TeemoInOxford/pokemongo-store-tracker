import os
import re
import json
import requests
from datetime import datetime
    
headers = {
    'User-Agent': 'Mozilla/5.0'
}

# ä» GitHub Secrets æˆ–ç¯å¢ƒå˜é‡è¯»å–ä»£ç†è®¾ç½®
def get_proxies():
    user = os.getenv("PROXY_USER")
    pwd = os.getenv("PROXY_PASS")
    host = os.getenv("PROXY_HOST")
    port = os.getenv("PROXY_PORT")

    if not all([user, pwd, host, port]):
        raise Exception("âŒ ç¼ºå°‘ä»£ç†ç¯å¢ƒå˜é‡")

    proxy_url = f"http://{user}:{pwd}@{host}:{port}"
    print(f"ğŸ›°ï¸ å½“å‰ä½¿ç”¨ä»£ç†åœ°å€: {host}:{port}")
    return {
        "http": proxy_url,
        "https": proxy_url
    }

# ä»é¡µé¢æºç ä¸­æå– buildIdï¼ˆæ¥è‡ª /_next/static/.../_buildManifest.jsï¼‰
def get_build_id(proxies):
    url = "https://store.pokemongo.com/"
    print(f"ğŸ” æ­£åœ¨è®¿é—®é¡µé¢è·å– buildId: {url}")
    resp = requests.get(url, headers=headers, proxies=proxies, timeout=10)

    print(f"ğŸ“„ é¡µé¢çŠ¶æ€ç : {resp.status_code}")
    if resp.status_code != 200:
        raise Exception(f"âŒ é¡µé¢è·å–å¤±è´¥ status={resp.status_code}")

    match = re.search(r'/_next/static/([a-zA-Z0-9\-_]+)/_ssgManifest\.js', resp.text)
    if match:
        build_id = match.group(1)
        print(f"âœ… æˆåŠŸæå– buildId: {build_id}")
        with open("build_id.json", "w", encoding="utf-8") as f:
            json.dump({
                "buildId": build_id,
                "timestamp": datetime.now().astimezone().isoformat()
            }, f, ensure_ascii=False, indent=2)
        print("ğŸ“„ å·²å†™å…¥ build_id.json")
        return build_id
    else:
        raise Exception("âŒ æ— æ³•åœ¨ HTML ä¸­æ‰¾åˆ° buildId")

# ä¸»çˆ¬è™«é€»è¾‘
def crawl():
    proxies = get_proxies()
    build_id = get_build_id(proxies)

    base_url = f"https://store.pokemongo.com/_next/data/{build_id}"
    urls = {
        "en": f"{base_url}/en.json",
        "zh": f"{base_url}/zh-Hant.json"
    }

    data = {}
    for lang, url in urls.items():
        print(f"ğŸŒ æŠ“å– {lang} æ•°æ®: {url}")
        resp = requests.get(url, headers=headers, proxies=proxies, timeout=10)
        print(f"â¡ï¸ çŠ¶æ€ç : {resp.status_code}")
        if resp.status_code == 200:
            data[lang] = resp.json()
        else:
            raise Exception(f"âŒ è¯·æ±‚å¤±è´¥: {url} - status: {resp.status_code}")

    with open("data.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
        print("âœ… æ•°æ®å·²å†™å…¥ data.json")

if __name__ == "__main__":
    crawl()
